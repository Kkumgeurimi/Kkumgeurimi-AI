# apps/main.py
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from openai import OpenAI
from pymongo import MongoClient
from sentence_transformers import SentenceTransformer
from datetime import datetime, timezone
from typing import List, Dict, Any, Optional

import numpy as np
import pandas as pd

import uuid
import tempfile
import os

import json
import re

import boto3
from botocore.exceptions import NoCredentialsError, ClientError

from . import config
from . import schemas

# ======= S3 ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ ===========
def download_from_s3(bucket: str, key: str) -> Optional[str]:
    """S3ì—ì„œ íŒŒì¼ì„ ê³ ìœ í•œ ì„ì‹œ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ê³ , ê·¸ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    # â­ï¸ ê²¹ì¹˜ì§€ ì•ŠëŠ” ê³ ìœ í•œ ì´ë¦„ì˜ ì„ì‹œ íŒŒì¼ ìƒì„±
    with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as temp_f:
        temp_file_path = temp_f.name
    
    print(f"Attempting to download s3://{bucket}/{key} to temporary file {temp_file_path}...")
    s3 = boto3.client('s3')
    try:
        s3.download_file(bucket, key, temp_file_path)
        print("âœ… Download successful.")
        # â­ï¸ ì„±ê³µ ì‹œ, ìƒì„±ëœ ì„ì‹œ íŒŒì¼ì˜ ê²½ë¡œë¥¼ ë°˜í™˜
        return temp_file_path
    except (NoCredentialsError, ClientError) as e:
        print(f"ğŸ”¥ Failed to download from S3: {e}")
        # ì‹¤íŒ¨ ì‹œ, ìƒì„±í–ˆë˜ ì„ì‹œ íŒŒì¼ ì‚­ì œ í›„ None ë°˜í™˜
        os.remove(temp_file_path)
        return None

# ======================================================================================
# 1. ì•± ì´ˆê¸°í™” ë° ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
# ======================================================================================
app = FastAPI(title="ì§„ë¡œ ì²´í—˜ ì¶”ì²œ ì±—ë´‡ API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_headers=["*"],
    allow_methods=["*"],
)

# ======================================================================================
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ======================================================================================
def fmt_price(v: Any) -> str:
    """ê°€ê²© í¬ë§·íŒ… ìœ í‹¸ë¦¬í‹°"""
    if v is None or str(v).strip() == "" or pd.isna(v):
        return "ë¯¸ì •"
    try:
        f = float(v)
        return "ë¬´ë£Œ" if f == 0 else f"{int(f):,}ì›"
    except (ValueError, TypeError):
        return str(v)

# ======================================================================================
# 3. FastAPI ì‹œì‘/ì¢…ë£Œ ì´ë²¤íŠ¸
# ======================================================================================
@app.on_event("startup")
def startup_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ DB ì—°ê²° ë° ëª¨ë¸/ë°ì´í„° ë¡œë“œ"""
    # MongoDB ì—°ê²°
    try:
        app.state.mcli = MongoClient(config.MONGO_URI)
        app.state.db = app.state.mcli[config.DB_NAME]
        app.state.users = app.state.db[config.USERS_COLLECTION]
        app.state.history = app.state.db[config.HISTORY_COLLECTION]
        # â­ï¸ ì¶”ì²œ ê¸°ë¡ ì»¬ë ‰ì…˜ ì´ˆê¸°í™”
        app.state.recommendations = app.state.db[config.RECOMMENDATIONS_COLLECTION]
        
        # ì¸ë±ìŠ¤ ì„¤ì •
        app.state.history.create_index([("student_id", 1), ("profession", 1), ("ts", -1)])
        # â­ï¸ ì¶”ì²œ ê¸°ë¡ ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤ ì¶”ê°€
        app.state.recommendations.create_index([("student_id", 1), ("ts", -1)])
        
        print("âœ… MongoDB connected successfully.")

    except Exception as e:
        print(f"ğŸ”¥ MongoDB connection failed: {e}")
        app.state.mcli = app.state.db = app.state.users = app.state.history = None

    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    app.state.oai_client = OpenAI(api_key=config.OPENAI_API_KEY) if config.OPENAI_API_KEY else None
    if app.state.oai_client: print("âœ… OpenAI client initialized.")
    else: print("âš ï¸ OpenAI client not available (API key missing).")

    # S3ì—ì„œ ìµœì‹  ì›ë³¸ CSV ë‹¤ìš´ë¡œë“œ
    local_csv_path = None # â­ï¸ ë³€ìˆ˜ ì´ˆê¸°í™”
    try:
        # â­ï¸ ê³ ìœ í•œ ì„ì‹œ íŒŒì¼ ê²½ë¡œë¥¼ ë°›ìŒ
        local_csv_path = download_from_s3(config.S3_BUCKET_NAME, config.S3_PROGRAM_CSV_KEY)
        if not local_csv_path:
            raise RuntimeError("ğŸ”¥ Failed to download program CSV from S3.")

        print(f"ğŸ’¿ Loading data from {local_csv_path}.")
        app.state.prog_df = pd.read_csv(local_csv_path, dtype={'program_id': str})
        app.state.prog_df = app.state.prog_df.replace({np.nan})
    finally:
        # â­ï¸ ì‘ì—…ì´ ì„±ê³µí•˜ë“  ì‹¤íŒ¨í•˜ë“ , ì‚¬ìš©ì´ ëë‚œ ì„ì‹œ íŒŒì¼ì€ ë°˜ë“œì‹œ ì‚­ì œ
        if local_csv_path and os.path.exists(local_csv_path):
            os.remove(local_csv_path)
            print(f"âœ… Cleaned up temporary file: {local_csv_path}")

    
    # ë¡œì»¬ì— ì €ì¥ëœ ì„ë² ë”© íŒŒì¼(.npy) ë¡œë“œ (ê²€ìƒ‰ìš©)
    if not config.ITEMS_NPY_PATH.exists():
        raise FileNotFoundError(f"Embeddings .npy file not found: {config.ITEMS_NPY_PATH}")
    
    print(f"âš¡ï¸ Loading pre-computed embeddings from: {config.ITEMS_NPY_PATH}")
    app.state.program_embeddings = np.load(config.ITEMS_NPY_PATH)
    
    print(f"ğŸ§  Loading embedding model: {config.EMBEDDING_MODEL}")
    app.state.embedding_model = SentenceTransformer(config.EMBEDDING_MODEL)
    print("âœ… All models and data are ready.")   

@app.on_event("shutdown")
def shutdown_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ DB ì—°ê²° í•´ì œ"""
    if app.state.mcli is not None:
        app.state.mcli.close()
        print("ğŸ”Œ MongoDB connection closed.")

# ======================================================================================
# 4. í•µì‹¬ ì„œë¹„ìŠ¤ ë¡œì§ (í•¨ìˆ˜ë¡œ ë¶„ë¦¬)
# ======================================================================================
def search_programs(query: str, profession: str, history_turns: List[Dict]) -> List[Dict]:
    """ëŒ€í™” ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ì§„ë¡œ ì²´í—˜ í”„ë¡œê·¸ë¨ì„ ê²€ìƒ‰"""

   # â­ï¸ ì‚¬ìš©ìì™€ AIì˜ ëŒ€í™”ë¥¼ ëª¨ë‘ í•©ì³ì„œ ì „ì²´ ë§¥ë½(context) ìƒì„±
    context_parts = []
    for turn in history_turns:
        context_parts.append(turn.get('query', ''))
        context_parts.append(turn.get('answer', ''))
    context_text = " ".join(context_parts)
    
    # ìµœì¢… ê²€ìƒ‰ì–´ = ì „ì²´ ëŒ€í™” ë§¥ë½ + í˜„ì¬ í•µì‹¬ ì§ˆë¬¸ + ì§ì—…
    full_query = f"{context_text} {query} {profession}"
   
    query_embedding = app.state.embedding_model.encode([full_query], normalize_embeddings=True)[0]
    sims = app.state.program_embeddings @ query_embedding
    
    top_k = getattr(config, 'DEFAULT_TOP_K', 3)
    matches = []
    seen_titles = set()
    num_candidates = top_k * 2 
    top_idx = np.argsort(-sims)[:num_candidates]

    for i in top_idx:
        row = app.state.prog_df.iloc[int(i)].to_dict()
        program_name = row.get("program_title")

        if program_name in seen_titles:
            continue
        
        seen_titles.add(program_name)

        output_data = {
	    "program_id": row.get("program_id"),
            "program_title": program_name,
            "provider": row.get("provider"),
            "start_date": row.get("start_date"),
            "end_date": row.get("end_date"),
            "program_type": row.get("program_type"),
            "target_audience": row.get("target_audience"),
	    "related_major": row.get("related_major"),
            "venue_region": row.get("venue_region"),
            "cost_type": row.get("cost_type"),
        #    "price": row.get("price"),
            "score": float(sims[int(i)])
        }
        matches.append(output_data)

        if len(matches) >= top_k:
            break
            
    return matches

def build_system_prompt(profession: str, name: Optional[str] = None) -> str:
    """LLMì˜ ì—­í• ì„ ì •ì˜í•˜ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    profession = (profession or "ì§„ë¡œ ìƒë‹´ ì „ë¬¸ê°€").strip()[:60]

    rules = (
        "1. ë‹¹ì‹ ì˜ ì—­í• : ë‹¹ì‹ ì€ '{profession}' ì§ì—…ì„ ê°€ì§„ ì „ë¬¸ê°€ì´ë©°, ì¤‘ê³ ë“±í•™ìƒë“¤ì—ê²Œ ì§„ë¡œ ìƒë‹´ì„ í•´ì£¼ëŠ” ì»¤ë¦¬ì–´ ë©˜í† ì…ë‹ˆë‹¤.\n"
        "2. ë§íˆ¬: í•­ìƒ ì¹œì ˆí•˜ê³  ë”°ëœ»í•œ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ì„¸ìš”. ì–´ë ¤ìš´ ì „ë¬¸ ìš©ì–´ëŠ” í”¼í•˜ê³ , í•™ìƒì˜ ëˆˆë†’ì´ì— ë§ì¶° ì‰½ê²Œ ì„¤ëª…í•´ì•¼ í•©ë‹ˆë‹¤.\n"
        "3. ëŒ€í™” ë§¥ë½ ìœ ì§€: ì´ì „ ëŒ€í™”ì˜ íë¦„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ì„¸ìš”.\n"
        "4. ì ˆëŒ€ ê·œì¹™: ì–´ë– í•œ ê²½ìš°ì—ë„ ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•(`*`, `-`, `#`, `1.` ë“±)ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ëª¨ë“  ë‹µë³€ì€ ì˜¤ì§ ì¼ë°˜ í…ìŠ¤íŠ¸(Plain Text)ì™€ ê°„ë‹¨í•œ ì¤„ë°”ê¿ˆìœ¼ë¡œë§Œ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤."
    ).format(profession=profession)

    # ì´ë¦„ì´ ì „ë‹¬ëœ ê²½ìš°, ê°œì¸í™” ê·œì¹™ ì¶”ê°€
    if name:
        personalization_rule = f"\n5. ê°œì¸í™”: í•™ìƒì˜ ì´ë¦„ì€ '{name}'ì…ë‹ˆë‹¤. ëŒ€í™” ì¤‘ì— '{name} ë‹˜' ë˜ëŠ” '{name} í•™ìƒ'ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ë¦„ì„ ë¶ˆëŸ¬ì£¼ë©° ì¹œê·¼í•˜ê²Œ ì‘ëŒ€í•´ì£¼ì„¸ìš”."
        rules += personalization_rule

    # 'ëª¨ë²” ë‹µì•ˆ' ì˜ˆì‹œ ì œê³µ
    good_example = (
        "### ëª¨ë²” ë‹µë³€ ì˜ˆì‹œ (ì´ëŸ° ìŠ¤íƒ€ì¼ë¡œ ë‹µë³€í•´ì•¼ í•¨):\n\n"
        "ì‚¬ìš©ì ì§ˆë¬¸: ì½”ë”©ì´ë‘ ë””ìì¸ ë‘˜ ë‹¤ ë°°ìš°ê³  ì‹¶ì€ë°, ë­ë¶€í„° í• ê¹Œìš”?\n\n"
        "ë‹¹ì‹ ì˜ ë‹µë³€: ë””ìì¸ê³¼ ì½”ë”© ë‘ ë¶„ì•¼ì— ëª¨ë‘ ê´€ì‹¬ì´ ìˆìœ¼ì‹œêµ°ìš”! ì •ë§ ë©‹ì§„ ì¡°í•©ì´ì—ìš”. ë‘ ë¶„ì•¼ì˜ ê³µí†µì ì¸ ì‚¬ìš©ì ê²½í—˜(UX)ì— ëŒ€í•´ ë¨¼ì € ì•Œì•„ë³´ëŠ” ê²ƒì„ ì¶”ì²œí•´ìš”. ê·¸ ë‹¤ìŒìœ¼ë¡œëŠ” í”¼ê·¸ë§ˆ ê°™ì€ ë””ìì¸ íˆ´ì„ ìµíˆê³ , ë§ˆì§€ë§‰ìœ¼ë¡œ ê°„ë‹¨í•œ ì›¹ì‚¬ì´íŠ¸ë¥¼ ë§Œë“¤ì–´ë³´ë©´ í° ë„ì›€ì´ ë  ê±°ì˜ˆìš”."
    )

    # ìµœì¢… í”„ë¡¬í”„íŠ¸ ì¡°í•©
    system_prompt = (
        f"## ì§€ì‹œì‚¬í•­\n{rules}\n\n"
        f"{good_example}"
    )
    
    return system_prompt

def build_user_prompt(query: str, profile: Dict) -> str:
    """LLMì— ì „ë‹¬í•  ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„± (í”„ë¡œê·¸ë¨ ì¶”ì²œ ì–¸ê¸‰ ì—†ìŒ)"""
    profile_parts = [f"ì´ë¦„:{profile.get('name', 'í•™ìƒ')}"]
    if profile.get('grade'): profile_parts.append(f"í•™ë…„:{profile.get('grade')}")
    if profile.get('interests'): profile_parts.append(f"ê´€ì‹¬ì‚¬:{', '.join(profile.get('interests'))}")
    profile_line = " / ".join(profile_parts)
    return (
        f"[í•™ìƒ í”„ë¡œí•„] {profile_line}\n"
        f"[í•™ìƒ ì§ˆë¬¸] {query}\n\n"
        "---"
        "ìœ„ í•™ìƒì˜ ì§ˆë¬¸ì— ëŒ€í•´, ì„¤ì •ëœ ì§ì—…ì¸ì˜ ì…ì¥ì—ì„œ ì¹œì ˆí•˜ê³  ë”°ëœ»í•˜ê²Œ ëŒ€ë‹µí•´ì¤˜."
    )

def run_llm_chat(system_prompt: str, history_turns: List[Dict], user_prompt: str) -> str:
    """OpenAI LLMì„ í˜¸ì¶œí•˜ì—¬ ë‹µë³€ ìƒì„±"""
    if app.state.oai_client is None: return ""
    messages = [{"role": "system", "content": system_prompt}]
    for turn in history_turns:
        messages.append({"role": "user", "content": turn["query"]})
        messages.append({"role": "assistant", "content": turn["answer"]})
    messages.append({"role": "user", "content": user_prompt})
    try:
        resp = app.state.oai_client.chat.completions.create(
            model=config.CHAT_MODEL, messages=messages, temperature=0.7, max_tokens=800,
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        print(f"ğŸ”¥ OpenAI API call failed: {e}")
        return ""

# â­ï¸ í•¨ìˆ˜ ì¸ì ë³€ê²½
def fetch_chat_history(student_id: str, profession: str) -> List[Dict[str, str]]:
    """MongoDBì—ì„œ ìµœê·¼ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ"""
    if app.state.history is None:
        return []
    cursor = app.state.history.find(
        # â­ï¸ DB ì¿¼ë¦¬ í•„ë“œ ë³€ê²½
        {"type": "chat", "student_id": student_id, "profession": profession}
    ).sort("ts", -1).limit(config.HISTORY_LIMIT)
    history_docs = list(cursor)[::-1]
    return [{"query": h.get("query", ""), "answer": h.get("answer", "")} for h in history_docs]


# 5. API ì—”ë“œí¬ì¸íŠ¸
# ======================================================================================
@app.get("/healthz")
def health_check():
    """ì„œë²„ ìƒíƒœ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "ok": True,
        "mongo_connected": app.state.db is not None,
        "models_loaded": hasattr(app.state, "embedding_model"),
        "program_count": len(app.state.prog_df) if hasattr(app.state, "prog_df") else 0,
    }



# â­ï¸ `/recommendations` ì—”ë“œí¬ì¸íŠ¸ ë¡œì§ ëŒ€í­ ìˆ˜ì •
@app.post("/recommendations", response_model=schemas.RecommendResp)
def get_recommendations(req: schemas.RecommendReq):
    """DBì˜ ì±„íŒ… ê¸°ë¡ ë˜ëŠ” professionì„ ë°”íƒ•ìœ¼ë¡œ í”„ë¡œê·¸ë¨ì„ ì¶”ì²œí•˜ê³  ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    
    history_turns = fetch_chat_history(req.student_id, req.profession)


    # â­ï¸ 1. ì±„íŒ… ê¸°ë¡ ìœ ë¬´ì— ë”°ë¼ ê²€ìƒ‰ ì¿¼ë¦¬ ê²°ì • (ìˆ˜ì •ëœ ë¡œì§)
    if not history_turns:
        # ê¸°ë¡ì´ ì—†ìœ¼ë©´ profession ìì²´ë¥¼ ê²€ìƒ‰ì–´ë¡œ ì‚¬ìš©
        search_query = req.profession
        print(f"No chat history for {req.student_id}. Recommending based on profession: {req.profession}")
    else:
        # ê¸°ë¡ì´ ìˆìœ¼ë©´ 'ê°€ì¥ ë§ˆì§€ë§‰ ì‚¬ìš©ì ì§ˆë¬¸'ì„ í•µì‹¬ ê²€ìƒ‰ì–´ë¡œ ì‚¬ìš©
        search_query = history_turns[-1]['query']
        print(f"Recommending for {req.student_id} based on last query: '{search_query}'")

    # â­ï¸ 2. search_programs í˜¸ì¶œ
    # search_query: í˜„ì¬ í•µì‹¬ ê²€ìƒ‰ì–´ (ëª©ì ì§€)
    # history_turns: ì „ì²´ ëŒ€í™” ë§¥ë½ (ì´ë™ ê²½ë¡œ)
    all_matches = search_programs(search_query, req.profession, history_turns)
    
    SCORE_THRESHOLD = 0.5
    top_matches = [m for m in all_matches if float(m.get("score", 0)) >= SCORE_THRESHOLD]
    if not top_matches and all_matches:
        top_matches = all_matches[:1]

    # â­ï¸ 3. ì¶”ì²œ ê²°ê³¼ë¥¼ DBì— ì €ì¥
    if top_matches and app.state.recommendations is not None:
        recommendation_id = str(uuid.uuid4()) # ì¶”ì²œ ì´ë²¤íŠ¸ ê³ ìœ  ID ìƒì„±
        docs_to_save = []
        for match in top_matches:
            docs_to_save.append({
                "program_recommendation_id": recommendation_id,
                "student_id": req.student_id,
		"profession": req.profession,
                "program_id": match.get("program_id"),
                "ts": datetime.now(timezone.utc)
            })
        
        try:
            app.state.recommendations.insert_many(docs_to_save)
            print(f"âœ… Saved {len(docs_to_save)} recommendations to DB for student {req.student_id}")
        except Exception as e:
            print(f"ğŸ”¥ Failed to save recommendations to DB: {e}")

    # â­ï¸ 2. ì‘ë‹µ ë©”ì‹œì§€ì™€ í•¨ê»˜ ìµœì¢… ê²°ê³¼ ë°˜í™˜
    return schemas.RecommendResp(
        message=f"{req.profession} ê´€ë ¨ í”„ë¡œê·¸ë¨ì„ ì¶”ì²œí•´ë“œë¦´ê²Œìš”!",
        top_matches=[schemas.ProgramMatch(**m) for m in top_matches]
    )



# â­ï¸ 2. ê¸°ì¡´ `/chat` ì—”ë“œí¬ì¸íŠ¸ ë‹¨ìˆœí™”
@app.post("/chat", response_model=schemas.ChatResp)
def chat(req: schemas.ChatReq):
    """LLMê³¼ ëŒ€í™”í•˜ê³ , ê·¸ ë‚´ìš©ì„ DBì— ì €ì¥í•©ë‹ˆë‹¤. (ì¶”ì²œ ê¸°ëŠ¥ ì—†ìŒ)"""
    
    query = (req.query or "").strip()
    if not query:
        raise HTTPException(status_code=400, detail="Query cannot be empty")

    history_turns = fetch_chat_history(req.student_id, req.profession)
    
    # --- ì¶”ì²œ ê´€ë ¨ ë¡œì§ ëª¨ë‘ ì œê±° ---
    
    profile: Dict[str, Any] = {}
    used_profile = False
    if app.state.users is not None and req.student_id:
        doc = app.state.users.find_one({"_id": req.student_id})
        if doc:
            profile = {**doc, "student_id": req.student_id}; profile.pop("_id", None); used_profile = True
    
    system_prompt = build_system_prompt(req.profession, req.name)
    user_prompt = build_user_prompt(query, profile)
    answer = run_llm_chat(system_prompt, history_turns, user_prompt)

    if not answer:
        answer = "ë¯¸ì•ˆ, ì§€ê¸ˆì€ ë‹µë³€í•˜ê¸° ì¡°ê¸ˆ ì–´ë ¤ì›Œ. ì ì‹œ í›„ì— ë‹¤ì‹œ ë¬¼ì–´ë´ ì¤„ë˜?"

    if app.state.history is not None:
        app.state.history.insert_one({
            "type": "chat", "student_id": req.student_id, "profession": req.profession,
            "query": query, "answer": answer, 
            "ts": datetime.now(timezone.utc),
        })

    # â­ï¸ ìˆœìˆ˜í•˜ê²Œ ë‹µë³€ë§Œ ë°˜í™˜
    return schemas.ChatResp(answer=answer)


@app.post("/profile/upsert", status_code=200)
def upsert_profile(p: schemas.Profile):
    """ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸"""
    if app.state.users is None:
        raise HTTPException(503, "MongoDB is not configured")
    # â­ï¸ p.student_id ì‚¬ìš©
    update_data = p.model_dump(exclude={"student_id"})
    app.state.users.update_one({"_id": p.student_id}, {"$set": update_data}, upsert=True)
    return {"ok": True}

# â­ï¸ ê²½ë¡œ ë³€ìˆ˜ ë° í•¨ìˆ˜ ì¸ì ë³€ê²½
@app.get("/profile/{student_id}", response_model=schemas.Profile)
def get_profile(student_id: str):
    """íŠ¹ì • ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ"""
    if app.state.users is None:
        raise HTTPException(503, "MongoDB is not configured")
    # â­ï¸ DB ì¿¼ë¦¬ í•„ë“œ ë³€ê²½
    doc = app.state.users.find_one({"_id": student_id})
    if not doc:
        raise HTTPException(404, "Profile not found")
    
    # â­ï¸ ë°˜í™˜ í•„ë“œëª… ë³€ê²½
    return schemas.Profile(student_id=doc.pop("_id"), **doc)

@app.post("/log/event", status_code=200)
def log_event(body: schemas.EventIn):
    """í´ë¼ì´ì–¸íŠ¸ì˜ ë‹¤ì–‘í•œ ì´ë²¤íŠ¸ë¥¼ DBì— ê¸°ë¡"""
    if app.state.history is None:
        raise HTTPException(503, "MongoDB is not configured")
    app.state.history.insert_one({
        "type": body.type,
        # â­ï¸ body.student_id ì‚¬ìš©
        "student_id": body.student_id,
        "payload": body.payload,
        "ts": datetime.now(timezone.utc),
    })
    return {"ok": True}

# ======================================================================================
# 6. ì»¤ë¦¬ì–´ë§µ API ì—”ë“œí¬ì¸íŠ¸
# ======================================================================================
@app.get("/careermap/{student_id}", response_model=schemas.CareerMapResponse)
def get_careermap(student_id: str):
    """í•™ìƒì˜ í”„ë¡œê·¸ë¨ ì°¸ì—¬ ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ì»¤ë¦¬ì–´ë§µ í‚¤ì›Œë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    
    # --- 1. S3ì—ì„œ í•™ìƒ ì°¸ì—¬ ì •ë³´ CSV ë‹¤ìš´ë¡œë“œ ë° ì²˜ë¦¬ ---
    local_participation_csv = None
    
    try:
        # ê³ ìœ í•œ ì„ì‹œ íŒŒì¼ ê²½ë¡œë¥¼ ë°›ìŒ
        local_participation_csv = download_from_s3(config.S3_BUCKET_NAME, config.S3_PARTICIPATION_CSV_KEY)
        if not local_participation_csv:
            raise HTTPException(status_code=503, detail="Could not load participation data.")

        participation_df = pd.read_csv(local_participation_csv, dtype={'program_id': str, 'student_id': str})
        
        # 1-1. í•´ë‹¹ í•™ìƒì˜ ë°ì´í„°ë§Œ í•„í„°ë§
        student_programs_df = participation_df[participation_df['student_id'] == student_id]
        
        if student_programs_df.empty:
            # ì°¸ì—¬ ê¸°ë¡ì´ ì—†ìœ¼ë©´ ë¹ˆ ê²°ê³¼ ë°˜í™˜
            return schemas.CareerMapResponse(student_id=student_id, results=[])

        # 1-2. ìµœì‹ ìˆœ(program_registration_idê°€ ë†’ì€ ìˆœ)ìœ¼ë¡œ ì •ë ¬ í›„ ìµœëŒ€ 7ê°œ ì„ íƒ
        recent_programs_df = student_programs_df.sort_values(
            by='program_registration_id', ascending=False
        ).head(7)
        
        # 1-3. GPTì— ë³´ë‚¼ í”„ë¡œê·¸ë¨ ì œëª© ëª©ë¡ê³¼, ë‚˜ì¤‘ì— ì‚¬ìš©í•  ID-ì œëª© ë§¤í•‘ ìƒì„±
        program_info_list = []
        for index, row in recent_programs_df.iterrows():
            title = row.get("program_title", "")
            major = row.get("related_major", "ì •ë³´ ì—†ìŒ")
            program_info_list.append(f"{title} (ê´€ë ¨ ì „ê³µ: {major})")

        # ë‚˜ì¤‘ì— ì‚¬ìš©í•  ID-ì œëª© ë§¤í•‘ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
        program_id_title_map = pd.Series(
            recent_programs_df.program_id.values, index=recent_programs_df.program_title
        ).to_dict()

    except Exception as e:
        print(f"ğŸ”¥ Failed to process participation CSV: {e}")
        raise HTTPException(status_code=500, detail="Error processing participation data.")

    finally:
        if local_participation_csv and os.path.exists(local_participation_csv):
            os.remove(local_participation_csv)
            print(f"âœ… Cleaned up temporary file: {local_participation_csv}")

    # --- 2. GPTì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ ìƒì„± ---
    program_list_str = "\n- ".join(program_info_list)
    prompt_for_gpt = (
        f"ë‹¹ì‹ ì€ í•™ìƒë“¤ì˜ í™œë™ ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ 'ë‚˜ì˜ ì§„ë¡œë§µ'ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ ì»¤ë¦¬ì–´ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.\n"
        f"í•™ìƒì´ ìµœê·¼ ì°¸ì—¬í•œ í”„ë¡œê·¸ë¨ ëª©ë¡ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n- {program_list_str}\n\n"
        f"ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ì´ í™œë™ë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬, í•™ìƒì˜ í•µì‹¬ ê´€ì‹¬ì‚¬ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í‚¤ì›Œë“œì™€ ê´€ë ¨ ì§ë¬´ë¥¼ ì°¾ì•„ë‚´ëŠ” ê²ƒì…ë‹ˆë‹¤.\n\n"
        f"## ì‘ì—… ì§€ì¹¨:\n"
        f"1. **í‚¤ì›Œë“œ ìƒì„±**: ì•„ë˜ ê·œì¹™ì— ë”°ë¼ 1~4ê°œì˜ 'í•µì‹¬ í‚¤ì›Œë“œ'ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n"
        f"    - **ê·œì¹™ 1**: í‚¤ì›Œë“œëŠ” ë°˜ë“œì‹œ ë‹¨ì–´ í•œ ê°œë¡œ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n"
        f"    - **ê·œì¹™ 2**: í‚¤ì›Œë“œëŠ” ì§„ë¡œ/ì§ì—…ê³¼ ê´€ë ¨ëœ ê°œë…ì´ì–´ì•¼ í•˜ì§€ë§Œ, 'ì„œë¹„ìŠ¤ ê¸°íšì'ì™€ ê°™ì€ êµ¬ì²´ì ì¸ ì§ì—…ëª…ì€ ì ˆëŒ€ í‚¤ì›Œë“œë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì¢‹ì€ ì˜ˆ: 'ì„œë¹„ìŠ¤ ê¸°íš', 'ì‚¬ìš©ì ê²½í—˜' / ë‚˜ìœ ì˜ˆ: 'ì„œë¹„ìŠ¤ ê¸°íšì')\n"
        f"2. **ì •ë³´ ìƒì„±**: ê° í‚¤ì›Œë“œì— ëŒ€í•´ ì•„ë˜ ì •ë³´ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.\n"
        f"   - `keyword_description`: í‚¤ì›Œë“œì— ëŒ€í•œ ê°„ê²°í•œ ì„¤ëª…, 3ë¬¸ì¥ ì´ë‚´.\n"
        f"   - `related_participated_programs`: ì œì‹œëœ í•™ìƒ ì°¸ì—¬ í”„ë¡œê·¸ë¨ ëª©ë¡ ì¤‘, í•´ë‹¹ í‚¤ì›Œë“œì™€ ì§ì ‘ ê´€ë ¨ëœ í”„ë¡œê·¸ë¨ì˜ 'ì œëª©'ë§Œ ì •í™•íˆ ê³¨ë¼ ë¦¬ìŠ¤íŠ¸ì— ë‹´ì•„ì£¼ì„¸ìš”.\n"
        f"   - `related_jobs`: í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ì§ë¬´ë¥¼ **ë‹¨ í•˜ë‚˜ë§Œ** ì œì•ˆí•˜ê³ , ì†Œê°œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”. ì†Œê°œëŠ” 3ë¬¸ì¥ ì´ë‚´ì—¬ì•¼ í•©ë‹ˆë‹¤.\n\n"
        f"## ì¶œë ¥ í˜•ì‹ (ë§¤ìš° ì¤‘ìš”):\n"
        f"ë°˜ë“œì‹œ ì•„ë˜ì˜ ì˜ˆì‹œì™€ ë™ì¼í•œ JSON êµ¬ì¡°ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ì ˆëŒ€ë¡œ JSON ê°ì²´ ì´ì™¸ì˜ ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¶€ê°€ì ì¸ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n\n"
        f"### ì˜ˆì‹œ:\n"
        f"{{\n"
        f'  "keywords": [\n'
        f'    {{\n'
        f'      "keyword": "ê¸°íš",\n'
        f'      "keyword_description": "ì‚¬ìš©ìì—ê²Œ í•„ìš”í•œ ì„œë¹„ìŠ¤ë¥¼ êµ¬ìƒí•˜ê³  êµ¬ì²´í™”í•˜ì—¬ ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.",\n'
        f'      "related_participated_programs": ["PM ì§ë¬´ ë©˜í† ë§", "ì‚¬ìš©ì ë¦¬ì„œì¹˜ ì›Œí¬ìƒµ"],\n'
        f'      "related_jobs": [\n'
        f'       {{ "job_title": "ì„œë¹„ìŠ¤ ê¸°íšì", "job_description": "ì‚¬ìš©ì ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì„¤ê³„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤." }}\n'
        f'      ]\n'
        f'    }},\n'
        f'    {{\n'
        f'      "keyword": "ì½˜í…ì¸ ",\n'
        f'      "keyword_description": "ê¸€, ì´ë¯¸ì§€, ì˜ìƒ ë“± ë‹¤ì–‘í•œ í˜•íƒœì˜ ì½˜í…ì¸ ë¥¼ í†µí•´ ë©”ì‹œì§€ë¥¼ ì „ë‹¬í•˜ëŠ” í™œë™ì…ë‹ˆë‹¤.",\n'
        f'      "related_participated_programs": ["ì½˜í…ì¸  ë§ˆì¼€íŒ… ìŠ¤ì¿¨"],\n'
        f'      "related_jobs": [\n'
        f'        {{ "job_title": "ì½˜í…ì¸  ë§ˆì¼€í„°", "job_description": "ê³ ê°ì—ê²Œ ìœ ìš©í•œ ì½˜í…ì¸ ë¥¼ í†µí•´ ë¸Œëœë“œì˜ ê°€ì¹˜ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤." }}\n'
        f'      ]\n'
        f'    }}\n'
        f'  ]\n'
        f'}}\n'
   )

    # --- 3. GPT í˜¸ì¶œ ë° ê²°ê³¼ íŒŒì‹± ---
    try:
        gpt_response_str = run_llm_chat("", [], prompt_for_gpt)
        
        # â­ï¸ 1. GPTì˜ ì›ë³¸ ì‘ë‹µì„ ê·¸ëŒ€ë¡œ ì¶œë ¥í•´ì„œ í™•ì¸ (ë””ë²„ê¹…ìš©)
        print("--- GPT Raw Response ---")
        print(gpt_response_str)
        print("------------------------")
        
        # â­ï¸ 2. JSON ë¶€ë¶„ë§Œ ë” ë˜‘ë˜‘í•˜ê²Œ ì¶”ì¶œ (ì •ê·œ í‘œí˜„ì‹ ì‚¬ìš©)
        match = re.search(r"\{.*\}", gpt_response_str, re.DOTALL)
        if not match:
            raise json.JSONDecodeError("No JSON object found in GPT response", gpt_response_str, 0)
        
        json_part = match.group(0)
        gpt_response_json = json.loads(json_part)

    except (json.JSONDecodeError, Exception) as e:
        print(f"ğŸ”¥ Failed to call or parse GPT response: {e}")
        return schemas.CareerMapResponse(student_id=student_id, results=[])

    # --- 4. GPT ê²°ê³¼ë¥¼ ìµœì¢… ì‘ë‹µ í˜•ì‹ìœ¼ë¡œ ì¡°ë¦½ ---
    final_results = []
    for item in gpt_response_json.get("keywords", []):
        # GPTê°€ ë°˜í™˜í•œ í”„ë¡œê·¸ë¨ ì œëª©ì„ ì‹¤ì œ program_idì™€ ë§¤í•‘
        related_programs_with_id = [
            schemas.ParticipatedProgram(
                program_id=program_id_title_map.get(title),
                program_title=title
            )
            for title in item.get("related_participated_programs", [])
            if title in program_id_title_map # GPTê°€ ì—†ëŠ” í”„ë¡œê·¸ë¨ì„ ì§€ì–´ë‚´ì§€ ì•Šë„ë¡ ë°©ì§€
        ]
        
        final_results.append(
            schemas.KeywordResult(
                keyword=item.get("keyword"),
                keyword_description=item.get("keyword_description"),
                related_participated_programs=related_programs_with_id,
                related_jobs=[schemas.RelatedJob(**job) for job in item.get("related_jobs", [])]
            )
        )
    
    return schemas.CareerMapResponse(student_id=student_id, results=final_results)


# ======================================================================================	
# 7. ì¶”ì²œ ë‚´ì—­ ì¡°íšŒ API ì—”ë“œí¬ì¸íŠ¸
# ======================================================================================
@app.get("/recommendations/history/{student_id}", response_model=schemas.RecommendationHistoryResponse)
def get_recommendation_history(student_id: str):
    """í•™ìƒ IDë¡œ ê³¼ê±°ì— ì¶”ì²œë°›ì•˜ë˜ í”„ë¡œê·¸ë¨ ëª©ë¡ ì „ì²´ë¥¼ 'ìµœì‹ ìˆœ'ìœ¼ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤."""
    
    if app.state.recommendations is None:
        raise HTTPException(status_code=503, detail="MongoDB is not configured")
        
    # â­ï¸ 1. MongoDBì—ì„œ 'ts'(timestamp)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìµœì‹ ìˆœ(-1)ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì¡°íšŒ
    recommended_docs = app.state.recommendations.find(
        {"student_id": student_id}
    ).sort("ts", -1)
    
    # â­ï¸ 2. ì¤‘ë³µì„ ì œê±°í•˜ë©´ì„œë„ ìˆœì„œë¥¼ ìœ ì§€í•˜ëŠ” ë¡œì§
    unique_ordered_ids = []
    seen_ids = set()
    for doc in recommended_docs:
        prog_id = doc.get('program_id')
        if prog_id and prog_id not in seen_ids:
            unique_ordered_ids.append(prog_id)
            seen_ids.add(prog_id)
    
    if not unique_ordered_ids:
        return schemas.RecommendationHistoryResponse(recommended_programs=[])

    # 3. pandas DataFrameì—ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    recommended_programs_df = app.state.prog_df[app.state.prog_df['program_id'].isin(unique_ordered_ids)]
    
    # â­ï¸ 4. ê²°ê³¼ë¥¼ MongoDBì—ì„œ ì¡°íšŒí•œ ìµœì‹ ìˆœìœ¼ë¡œ ë‹¤ì‹œ ì •ë ¬
    # program_idë¥¼ ì¹´í…Œê³ ë¦¬ íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ìˆœì„œë¥¼ ì§€ì •
    recommended_programs_df['program_id'] = pd.Categorical(recommended_programs_df['program_id'], categories=unique_ordered_ids, ordered=True)
    sorted_df = recommended_programs_df.sort_values('program_id')
    sorted_df = sorted_df.replace({np.nan: None})
    
    recommended_programs_list = sorted_df.to_dict('records')

    return schemas.RecommendationHistoryResponse(
        recommended_programs=[schemas.ProgramMatch(**prog) for prog in recommended_programs_list]
    )
