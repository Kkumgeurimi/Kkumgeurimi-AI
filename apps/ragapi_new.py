# apps/main.py
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from openai import OpenAI
from pymongo import MongoClient
from sentence_transformers import SentenceTransformer
from datetime import datetime, timezone
from typing import List, Dict, Any

import numpy as np
import pandas as pd

import uuid

import boto3
from botocore.exceptions import NoCredentialsError, ClientError

from . import config
from . import schemas

# ======= S3 ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ ===========
def download_from_s3(bucket: str, key: str, local_path: str) -> bool:
    print(f"Downloading s3://{bucket}/{key} to {local_path}...")
    s3 = boto3.client('s3')
    try:
        s3.download_file(bucket, key, local_path)
        print("âœ… Download successful.")
        return True
    except (NoCredentialsError, ClientError) as e:
        print(f"ğŸ”¥ Failed to download from S3: {e}")
        return False

# ======================================================================================
# 1. ì•± ì´ˆê¸°í™” ë° ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
# ======================================================================================
app = FastAPI(title="ì§„ë¡œ ì²´í—˜ ì¶”ì²œ ì±—ë´‡ API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_headers=["*"],
    allow_methods=["*"],
)

# ======================================================================================
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ======================================================================================
def fmt_price(v: Any) -> str:
    """ê°€ê²© í¬ë§·íŒ… ìœ í‹¸ë¦¬í‹°"""
    if v is None or str(v).strip() == "" or pd.isna(v):
        return "ë¯¸ì •"
    try:
        f = float(v)
        return "ë¬´ë£Œ" if f == 0 else f"{int(f):,}ì›"
    except (ValueError, TypeError):
        return str(v)

# ======================================================================================
# 3. FastAPI ì‹œì‘/ì¢…ë£Œ ì´ë²¤íŠ¸
# ======================================================================================
@app.on_event("startup")
def startup_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ DB ì—°ê²° ë° ëª¨ë¸/ë°ì´í„° ë¡œë“œ"""
    # MongoDB ì—°ê²°
    try:
        app.state.mcli = MongoClient(config.MONGO_URI)
        app.state.db = app.state.mcli[config.DB_NAME]
        app.state.users = app.state.db[config.USERS_COLLECTION]
        app.state.history = app.state.db[config.HISTORY_COLLECTION]
        # â­ï¸ ì¶”ì²œ ê¸°ë¡ ì»¬ë ‰ì…˜ ì´ˆê¸°í™”
        app.state.recommendations = app.state.db[config.RECOMMENDATIONS_COLLECTION]
        
        # ì¸ë±ìŠ¤ ì„¤ì •
        app.state.history.create_index([("student_id", 1), ("profession", 1), ("ts", -1)])
        # â­ï¸ ì¶”ì²œ ê¸°ë¡ ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤ ì¶”ê°€
        app.state.recommendations.create_index([("student_id", 1), ("ts", -1)])
        
        print("âœ… MongoDB connected successfully.")

    except Exception as e:
        print(f"ğŸ”¥ MongoDB connection failed: {e}")
        app.state.mcli = app.state.db = app.state.users = app.state.history = None

    # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    app.state.oai_client = OpenAI(api_key=config.OPENAI_API_KEY) if config.OPENAI_API_KEY else None
    if app.state.oai_client: print("âœ… OpenAI client initialized.")
    else: print("âš ï¸ OpenAI client not available (API key missing).")

    # S3ì—ì„œ ìµœì‹  ì›ë³¸ CSV ë‹¤ìš´ë¡œë“œ (í™”ë©´ í‘œì‹œìš©)
    local_csv_path = "downloaded_program_data.csv"
    if not download_from_s3(config.S3_BUCKET_NAME, config.S3_PROGRAM_CSV_KEY, local_csv_path):
        raise RuntimeError("ğŸ”¥ Failed to download program CSV from S3. Server cannot start.")

    print(f"ğŸ’¿ Loading data from {local_csv_path}.")
    app.state.prog_df = pd.read_csv(local_csv_path, dtype={'program_id':str})
    
    # ë¡œì»¬ì— ì €ì¥ëœ ì„ë² ë”© íŒŒì¼(.npy) ë¡œë“œ (ê²€ìƒ‰ìš©)
    if not config.ITEMS_NPY_PATH.exists():
        raise FileNotFoundError(f"Embeddings .npy file not found: {config.ITEMS_NPY_PATH}")
    
    print(f"âš¡ï¸ Loading pre-computed embeddings from: {config.ITEMS_NPY_PATH}")
    app.state.program_embeddings = np.load(config.ITEMS_NPY_PATH)
    
    print(f"ğŸ§  Loading embedding model: {config.EMBEDDING_MODEL}")
    app.state.embedding_model = SentenceTransformer(config.EMBEDDING_MODEL)
    print("âœ… All models and data are ready.")   

@app.on_event("shutdown")
def shutdown_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ DB ì—°ê²° í•´ì œ"""
    if app.state.mcli is not None:
        app.state.mcli.close()
        print("ğŸ”Œ MongoDB connection closed.")

# ======================================================================================
# 4. í•µì‹¬ ì„œë¹„ìŠ¤ ë¡œì§ (í•¨ìˆ˜ë¡œ ë¶„ë¦¬)
# ======================================================================================
def search_programs(query: str, profession: str, history_turns: List[Dict]) -> List[Dict]:
    """ëŒ€í™” ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ì§„ë¡œ ì²´í—˜ í”„ë¡œê·¸ë¨ì„ ê²€ìƒ‰"""
    context_text = " ".join(turn["query"] for turn in history_turns)
    full_query = f"{context_text} {query} {profession}"
    query_embedding = app.state.embedding_model.encode([full_query], normalize_embeddings=True)[0]
    sims = app.state.program_embeddings @ query_embedding
    
    top_k = getattr(config, 'DEFAULT_TOP_K', 3)
    matches = []
    seen_titles = set()
    num_candidates = top_k * 2 
    top_idx = np.argsort(-sims)[:num_candidates]

    for i in top_idx:
        row = app.state.prog_df.iloc[int(i)].to_dict()
        program_name = row.get("program_title")

        if program_name in seen_titles:
            continue
        
        seen_titles.add(program_name)

        output_data = {
	    "program_id": row.get("program_id"),
            "title": program_name,
            "provider": row.get("provider"),
            "date": row.get("ì²´í—˜ì¼"),
            "program_type": row.get("program_type"),
            "target_audience": row.get("target_audience"),
	    "major": row.get("related_major"),
            "region": row.get("venue_region"),
            "fee": row.get("price"),
            "score": float(sims[int(i)])
        }
        matches.append(output_data)

        if len(matches) >= top_k:
            break
            
    return matches

def build_system_prompt(profession: str) -> str:
    """LLMì˜ ì—­í• ì„ ì •ì˜í•˜ëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    profession = (profession or "ì§„ë¡œ ìƒë‹´ ì „ë¬¸ê°€").strip()[:60]
    return (
        f"ë„ˆëŠ” '{profession}'ë¼ëŠ” ì§ì—…ì„ ê°€ì§„ ì „ë¬¸ê°€ì•¼. ì¤‘ê³ ë“±í•™ìƒë“¤ì—ê²Œ ì§„ë¡œ ìƒë‹´ì„ í•´ì¤˜. "
        "ì–´ë ¤ìš´ ìš©ì–´ ëŒ€ì‹  ì¹œì ˆí•˜ê³  ë”°ëœ»í•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•´. í•™ìƒì˜ ìƒí™©ì— ë§ëŠ” ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ í•´ì£¼ê³ , "
        "ì´ì „ ëŒ€í™”ì˜ íë¦„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ì¤˜. ì ˆëŒ€ë¡œ ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì€ ì“°ì§€ ë§ˆ."
    )

def build_user_prompt(query: str, profile: Dict) -> str:
    """LLMì— ì „ë‹¬í•  ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„± (í”„ë¡œê·¸ë¨ ì¶”ì²œ ì–¸ê¸‰ ì—†ìŒ)"""
    profile_parts = [f"ì´ë¦„:{profile.get('name', 'í•™ìƒ')}"]
    if profile.get('grade'): profile_parts.append(f"í•™ë…„:{profile.get('grade')}")
    if profile.get('interests'): profile_parts.append(f"ê´€ì‹¬ì‚¬:{', '.join(profile.get('interests'))}")
    profile_line = " / ".join(profile_parts)
    return (
        f"[í•™ìƒ í”„ë¡œí•„] {profile_line}\n"
        f"[í•™ìƒ ì§ˆë¬¸] {query}\n\n"
        "---"
        "ìœ„ í•™ìƒì˜ ì§ˆë¬¸ì— ëŒ€í•´, ì„¤ì •ëœ ì§ì—…ì¸ì˜ ì…ì¥ì—ì„œ ì¹œì ˆí•˜ê³  ë”°ëœ»í•˜ê²Œ ëŒ€ë‹µí•´ì¤˜."
    )

def run_llm_chat(system_prompt: str, history_turns: List[Dict], user_prompt: str) -> str:
    """OpenAI LLMì„ í˜¸ì¶œí•˜ì—¬ ë‹µë³€ ìƒì„±"""
    if app.state.oai_client is None: return ""
    messages = [{"role": "system", "content": system_prompt}]
    for turn in history_turns:
        messages.append({"role": "user", "content": turn["query"]})
        messages.append({"role": "assistant", "content": turn["answer"]})
    messages.append({"role": "user", "content": user_prompt})
    try:
        resp = app.state.oai_client.chat.completions.create(
            model=config.CHAT_MODEL, messages=messages, temperature=0.7, max_tokens=800,
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        print(f"ğŸ”¥ OpenAI API call failed: {e}")
        return ""

# â­ï¸ í•¨ìˆ˜ ì¸ì ë³€ê²½
def fetch_chat_history(student_id: str, profession: str) -> List[Dict[str, str]]:
    """MongoDBì—ì„œ ìµœê·¼ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ"""
    if app.state.history is None:
        return []
    cursor = app.state.history.find(
        # â­ï¸ DB ì¿¼ë¦¬ í•„ë“œ ë³€ê²½
        {"type": "chat", "student_id": student_id, "profession": profession}
    ).sort("ts", -1).limit(config.HISTORY_LIMIT)
    history_docs = list(cursor)[::-1]
    return [{"query": h.get("query", ""), "answer": h.get("answer", "")} for h in history_docs]


# 5. API ì—”ë“œí¬ì¸íŠ¸
# ======================================================================================
@app.get("/healthz")
def health_check():
    """ì„œë²„ ìƒíƒœ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "ok": True,
        "mongo_connected": app.state.db is not None,
        "models_loaded": hasattr(app.state, "embedding_model"),
        "program_count": len(app.state.prog_df) if hasattr(app.state, "prog_df") else 0,
    }



# â­ï¸ `/recommendations` ì—”ë“œí¬ì¸íŠ¸ ë¡œì§ ëŒ€í­ ìˆ˜ì •
@app.post("/recommendations", response_model=schemas.RecommendResp)
def get_recommendations(req: schemas.RecommendReq):
    """DBì˜ ì±„íŒ… ê¸°ë¡ ë˜ëŠ” professionì„ ë°”íƒ•ìœ¼ë¡œ í”„ë¡œê·¸ë¨ì„ ì¶”ì²œí•˜ê³  ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    
    history_turns = fetch_chat_history(req.student_id, req.profession)
    
    # â­ï¸ 1. ì±„íŒ… ê¸°ë¡ ìœ ë¬´ì— ë”°ë¼ ê²€ìƒ‰ ì¿¼ë¦¬ ê²°ì •
    if not history_turns:
        # ê¸°ë¡ì´ ì—†ìœ¼ë©´ profession ìì²´ë¥¼ ê²€ìƒ‰ì–´ë¡œ ì‚¬ìš©
        search_query = req.profession
        print(f"No chat history for {req.student_id}. Recommending based on profession: {req.profession}")
    else:
        # ê¸°ë¡ì´ ìˆìœ¼ë©´ ìµœê·¼ ëŒ€í™” ë‚´ìš©ì„ ê²€ìƒ‰ì–´ë¡œ ì‚¬ìš©
        search_query = " ".join(turn['query'] for turn in history_turns)
        print(f"Recommending for {req.student_id} based on chat history.")

    all_matches = search_programs(search_query, req.profession, history_turns)
    
    SCORE_THRESHOLD = 0.5
    top_matches = [m for m in all_matches if float(m.get("score", 0)) >= SCORE_THRESHOLD]
    if not top_matches and all_matches:
        top_matches = all_matches[:1]

    # â­ï¸ 3. ì¶”ì²œ ê²°ê³¼ë¥¼ DBì— ì €ì¥
    if top_matches and app.state.recommendations is not None:
        recommendation_id = str(uuid.uuid4()) # ì¶”ì²œ ì´ë²¤íŠ¸ ê³ ìœ  ID ìƒì„±
        docs_to_save = []
        for match in top_matches:
            docs_to_save.append({
                "program_recommendation_id": recommendation_id,
                "student_id": req.student_id,
		"profession": req.profession,
                "program_id": match.get("program_id"),
                "ts": datetime.now(timezone.utc)
            })
        
        try:
            app.state.recommendations.insert_many(docs_to_save)
            print(f"âœ… Saved {len(docs_to_save)} recommendations to DB for student {req.student_id}")
        except Exception as e:
            print(f"ğŸ”¥ Failed to save recommendations to DB: {e}")

    # â­ï¸ 2. ì‘ë‹µ ë©”ì‹œì§€ì™€ í•¨ê»˜ ìµœì¢… ê²°ê³¼ ë°˜í™˜
    return schemas.RecommendResp(
        message=f"{req.profession} ê´€ë ¨ í”„ë¡œê·¸ë¨ì„ ì¶”ì²œí•´ë“œë¦´ê²Œìš”!",
        top_matches=[schemas.ProgramMatch(**m) for m in top_matches]
    )



# â­ï¸ 2. ê¸°ì¡´ `/chat` ì—”ë“œí¬ì¸íŠ¸ ë‹¨ìˆœí™”
@app.post("/chat", response_model=schemas.ChatResp)
def chat(req: schemas.ChatReq):
    """LLMê³¼ ëŒ€í™”í•˜ê³ , ê·¸ ë‚´ìš©ì„ DBì— ì €ì¥í•©ë‹ˆë‹¤. (ì¶”ì²œ ê¸°ëŠ¥ ì—†ìŒ)"""
    
    query = (req.query or "").strip()
    if not query:
        raise HTTPException(status_code=400, detail="Query cannot be empty")

    history_turns = fetch_chat_history(req.student_id, req.profession)
    
    # --- ì¶”ì²œ ê´€ë ¨ ë¡œì§ ëª¨ë‘ ì œê±° ---
    
    profile: Dict[str, Any] = {}
    used_profile = False
    if app.state.users is not None and req.student_id:
        doc = app.state.users.find_one({"_id": req.student_id})
        if doc:
            profile = {**doc, "student_id": req.student_id}; profile.pop("_id", None); used_profile = True
    
    system_prompt = build_system_prompt(req.profession)
    user_prompt = build_user_prompt(query, profile)
    answer = run_llm_chat(system_prompt, history_turns, user_prompt)

    if not answer:
        answer = "ë¯¸ì•ˆ, ì§€ê¸ˆì€ ë‹µë³€í•˜ê¸° ì¡°ê¸ˆ ì–´ë ¤ì›Œ. ì ì‹œ í›„ì— ë‹¤ì‹œ ë¬¼ì–´ë´ ì¤„ë˜?"

    if app.state.history is not None:
        app.state.history.insert_one({
            "type": "chat", "student_id": req.student_id, "profession": req.profession,
            "query": query, "answer": answer, 
            "ts": datetime.now(timezone.utc),
        })

    # â­ï¸ ìˆœìˆ˜í•˜ê²Œ ë‹µë³€ë§Œ ë°˜í™˜
    return schemas.ChatResp(answer=answer)


@app.post("/profile/upsert", status_code=200)
def upsert_profile(p: schemas.Profile):
    """ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸"""
    if app.state.users is None:
        raise HTTPException(503, "MongoDB is not configured")
    # â­ï¸ p.student_id ì‚¬ìš©
    update_data = p.model_dump(exclude={"student_id"})
    app.state.users.update_one({"_id": p.student_id}, {"$set": update_data}, upsert=True)
    return {"ok": True}

# â­ï¸ ê²½ë¡œ ë³€ìˆ˜ ë° í•¨ìˆ˜ ì¸ì ë³€ê²½
@app.get("/profile/{student_id}", response_model=schemas.Profile)
def get_profile(student_id: str):
    """íŠ¹ì • ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ"""
    if app.state.users is None:
        raise HTTPException(503, "MongoDB is not configured")
    # â­ï¸ DB ì¿¼ë¦¬ í•„ë“œ ë³€ê²½
    doc = app.state.users.find_one({"_id": student_id})
    if not doc:
        raise HTTPException(404, "Profile not found")
    
    # â­ï¸ ë°˜í™˜ í•„ë“œëª… ë³€ê²½
    return schemas.Profile(student_id=doc.pop("_id"), **doc)

@app.post("/log/event", status_code=200)
def log_event(body: schemas.EventIn):
    """í´ë¼ì´ì–¸íŠ¸ì˜ ë‹¤ì–‘í•œ ì´ë²¤íŠ¸ë¥¼ DBì— ê¸°ë¡"""
    if app.state.history is None:
        raise HTTPException(503, "MongoDB is not configured")
    app.state.history.insert_one({
        "type": body.type,
        # â­ï¸ body.student_id ì‚¬ìš©
        "student_id": body.student_id,
        "payload": body.payload,
        "ts": datetime.now(timezone.utc),
    })
    return {"ok": True}
